{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a4c34-c356-4cfe-a426-eb33b07ada83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import math\n",
    "#import pandas_ta as ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc07286-f3d5-4a2a-a074-4f5d4745472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setup (default values in the original indicator)\n",
    "length = 20\n",
    "mult = 2\n",
    "length_KC = 21\n",
    "mult_KC = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c98087-bc27-49bf-aabe-c585e72cef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"AAPL\")\n",
    "print(stock.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451d714-2f78-4dd4-a908-8558dba737ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = stock.history(period=\"3y\", interval='1d')\n",
    "stock_df.index.duplicated().sum()\n",
    "df_stock = stock_df.loc[~stock_df.index.duplicated(keep='first')]\n",
    "df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab323be-75fe-4cbe-a8ac-008b6fa6f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df_wk = stock.history(period=\"3y\", interval='1wk')\n",
    "stock_df.index.duplicated().sum()\n",
    "df_stock_wk = stock_df_wk.loc[~stock_df_wk.index.duplicated(keep='first')]\n",
    "df_stock_wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b884197-bbd4-4226-9190-d705908d1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df_mo = stock.history(period=\"3y\", interval='1mo')\n",
    "stock_df_mo.index.duplicated().sum()\n",
    "df_stock_mo = stock_df_mo.loc[~stock_df_mo.index.duplicated(keep='first')]\n",
    "df_stock_mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212983c4-a74e-44b6-832e-217a5430f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Bollinger Bands\n",
    "# moving average\n",
    "m_avg = df_stock['Close'].rolling(window=length).mean()\n",
    "# standard deviation\n",
    "m_std = df_stock['Close'].rolling(window=length).std(ddof=0)\n",
    "# upper Bollinger Bands\n",
    "df_stock['upper_BB'] = m_avg + mult * m_std\n",
    "# lower Bollinger Bands \n",
    "df_stock['lower_BB'] = m_avg - mult * m_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223ae98-b303-4219-b4b2-57de419937cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Keltner Channel\n",
    "# first we need to calculate True Range\n",
    "df_stock['tr0'] = abs(df_stock[\"High\"] - df_stock[\"Low\"])\n",
    "df_stock['tr1'] = abs(df_stock[\"High\"] - df_stock[\"Close\"].shift())\n",
    "df_stock['tr2'] = abs(df_stock[\"Low\"] - df_stock[\"Close\"].shift())\n",
    "df_stock['tr'] = df_stock[['tr0', 'tr1', 'tr2']].max(axis=1)\n",
    "# moving average of the TR\n",
    "range_ma = df_stock['tr'].rolling(window=length_KC).mean()\n",
    "# upper Keltner Channel\n",
    "df_stock['upper_KC'] = m_avg + range_ma * mult_KC\n",
    "# lower Keltner Channel\n",
    "df_stock['lower_KC'] = m_avg - range_ma * mult_KC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186892f-8563-4765-855f-12173df9f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADX Calculations\n",
    "\n",
    "plus_dm = df_stock[\"High\"].diff()\n",
    "minus_dm = df_stock[\"Low\"].diff()\n",
    "plus_dm[plus_dm < 0] = 0\n",
    "minus_dm[minus_dm > 0] = 0\n",
    "\n",
    "df_stock['atr'] = df_stock['tr'].rolling(window=14).mean()\n",
    "df_stock['plus_di'] = 100 * (plus_dm.ewm(alpha = 1/14).mean() / df_stock['atr'])\n",
    "df_stock['minus_di'] = abs(100 * (minus_dm.ewm(alpha = 1/14).mean() / df_stock['atr']))\n",
    "dx = (abs(df_stock['plus_di'] - df_stock['minus_di']) / abs(df_stock['plus_di'] + df_stock['minus_di'])) * 100\n",
    "adx = ((dx.shift(1) * (14 - 1)) + dx) / 14\n",
    "df_stock['adx'] = adx.ewm(alpha = 1/14).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54dc30-1c82-4f79-8281-df073471006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for 'squeeze'\n",
    "df_stock['squeeze_on'] = (df_stock['lower_BB'] > df_stock['lower_KC']) & (df_stock['upper_BB'] < df_stock['upper_KC'])\n",
    "df_stock['squeeze_off'] = (df_stock['lower_BB'] < df_stock['lower_KC']) & (df_stock['upper_BB'] > df_stock['upper_KC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "50cce3c0-c1f7-441c-b7c3-7b7ad8f1a7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits',\n",
       "       'upper_BB', 'lower_BB', 'tr0', 'tr1', 'tr2', 'tr', 'upper_KC',\n",
       "       'lower_KC', 'atr', 'plus_di', 'minus_di', 'adx', 'squeeze_on',\n",
       "       'squeeze_off', 'value', 'pct_change', 'profitable?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Momentum\n",
    "highest = df_stock['High'].rolling(window = length_KC).max()\n",
    "lowest = df_stock['Low'].rolling(window = length_KC).min()\n",
    "m1 = (highest + lowest) / 2\n",
    "df_stock['value'] = (df_stock['Close'] - (m1 + m_avg)/2)\n",
    "fit_y = np.array(range(0,length_KC))\n",
    "df_stock['value'] = df_stock['value'].rolling(window = length_KC).apply(lambda x : np.polyfit(fit_y, x, 1)[0] * (length_KC-1) +\n",
    "   np.polyfit(fit_y, x, 1)[1], raw=True)\n",
    "\n",
    "df_stock[['squeeze_on', 'squeeze_off']] = (df_stock[['squeeze_on', 'squeeze_off']] == True).astype(int)\n",
    "\n",
    "df_stock[\"pct_change\"] = df_stock['Close'].pct_change()\n",
    "\n",
    "\"\"\"\n",
    "conditions = [\n",
    "    (df_stock['pct_change'] > 0) | (df_stock['squeeze_on'] == 1),\n",
    "    (df_stock['pct_change'] < 0) | (df_stock['squeeze_on'] == 0)\n",
    "]\n",
    "\"\"\"\n",
    "conditions =  [\n",
    "    (df_stock['pct_change'] > 0),\n",
    "    (df_stock['pct_change'] < 0)\n",
    "]\n",
    "\n",
    "label = [1, 0]\n",
    "df_stock['profitable?'] = np.select(conditions, label) \n",
    "df_stock.dropna(inplace=True)\n",
    "df_stock.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ee155-e600-4005-b03a-8c98898f28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point for long position:\n",
    "# 1. black cross becomes gray (the squeeze is released)\n",
    "long_cond1 = (df_stock['squeeze_off'][-2] == 0) | (df_stock['squeeze_off'][-1] == 1) \n",
    "# 2. bar value is positive => the bar is light green\n",
    "long_cond2 = df_stock['value'][-1] > 0\n",
    "\n",
    "enter_long = long_cond1 and long_cond2\n",
    "# entry point for short position:\n",
    "# 1. black cross becomes gray (the squeeze is released)\n",
    "short_cond1 = (df_stock['squeeze_off'][-2] == 0) | (df_stock['squeeze_off'][-1] == 1) \n",
    "# 2. bar value is negative => the bar is light red \n",
    "short_cond2 = df_stock['value'][-1] < 0\n",
    "enter_short = short_cond1 and short_cond2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8a0d9-7958-40fe-ae72-ccf1f96bc46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc846d7-e83e-4484-8585-557dffb39ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohcl = df_stock[['Open', 'High', 'Close', 'Low']]\n",
    "ohcl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85756aff-cb29-4810-bdd3-bf12b4843783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add colors for the 'value bar'\n",
    "colors = []\n",
    "for ind, val in enumerate(df_stock['value']):\n",
    "  if val >= 0:\n",
    "    color = 'blue'\n",
    "    if val > df_stock['value'][ind-1]:\n",
    "      color = 'cyan'\n",
    "  else:\n",
    "    color = 'yellow'\n",
    "    if val < df_stock['value'][ind-1]:\n",
    "      color='red'\n",
    "  colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d093c-69ec-48b6-af7c-1f5305d42da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2 subplots: 1. bars, 2. crosses\n",
    "apds = [mpf.make_addplot(df_stock['value'], panel=1, type='bar', color=colors, alpha=0.8, secondary_y=False),\n",
    "        mpf.make_addplot([0] * len(df_stock), panel=1, type='scatter', marker='o', markersize=50, color=['gray' if s else 'red' for s in df_stock['squeeze_off']], secondary_y=False),\n",
    "        mpf.make_addplot(df_stock[['upper_BB']], color = 'red'),\n",
    "        mpf.make_addplot(df_stock[['lower_BB']], color = 'red'),\n",
    "        mpf.make_addplot(df_stock[['upper_KC']], color = 'blue'),\n",
    "        mpf.make_addplot(df_stock[['lower_KC']], color = 'blue'),\n",
    "        mpf.make_addplot(df_stock[['adx']], panel=2, color = 'purple', secondary_y=False),\n",
    "        mpf.make_addplot(df_stock[['plus_di']], panel=2, color = 'green', secondary_y=False),\n",
    "        mpf.make_addplot(df_stock[['minus_di']], panel=2, color = 'orange', secondary_y=False)]\n",
    "\n",
    "# plot ohcl with subplots\n",
    "fig, axes = mpf.plot(ohcl, \n",
    "              volume_panel = 2,\n",
    "              figratio=(2,1),\n",
    "              figscale=1,\n",
    "              mav = (8,21,34),\n",
    "              type='candle', \n",
    "              addplot=apds,\n",
    "              returnfig=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2693e5f4-9018-4460-b794-fa6e5c3c1f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profitable?\n",
       "1              368\n",
       "0              306\n",
       "dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Create our features\n",
    "X = df_stock.copy()\n",
    "X.drop(columns=['profitable?',\"squeeze_off\",\"tr0\",\"tr1\",\"tr2\",\"tr\",\"Dividends\",\"Stock Splits\",'plus_di','minus_di'], axis=1, inplace=True)\n",
    "\n",
    "# Create our target\n",
    "y = df_stock[['profitable?']]\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8b5cba5d-09b5-407f-aa83-081835061602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 14)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "618bc855-0638-4730-b0df-0683ab62bc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profitable?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-08</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-08</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            profitable?\n",
       "Date                   \n",
       "2020-05-08            1\n",
       "2019-06-05            1\n",
       "2021-01-20            1\n",
       "2020-11-27            1\n",
       "2018-12-17            0\n",
       "...                 ...\n",
       "2021-04-08            1\n",
       "2020-09-03            0\n",
       "2020-03-26            1\n",
       "2020-05-28            1\n",
       "2019-10-10            1\n",
       "\n",
       "[505 rows x 1 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ebf83acc-a11d-4694-b956-3a0aa309b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0d6eb77c-1647-44b9-a8ce-10f8533a4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d98ae0d2-4056-4095-95ed-97fe03c821ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9d07013b-8529-4f5b-adb8-b2650faf9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "X_trained_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f297a80f-44a1-4bc8-8cd0-af63aaea109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators = 100, random_state = 1)\n",
    "rf_model = rf_model.fit(X_trained_scaled, y_train)\n",
    "predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6ff50ea1-8da9-4308-ae53-2fb89f980e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7fd14ae6-6bff-4124-baba-018c89d0a500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77,  0],\n",
       "       [ 0, 92]], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "74f43ae0-553f-4127-b836-6f03a73fe855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      1.00      1.00      1.00      1.00        77\n",
      "          1       1.00      1.00      1.00      1.00      1.00      1.00        92\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1.00      1.00      1.00       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "da2d1927-57b0-428e-8fa7-9bf254ea5bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8078107854801957, 'pct_change'),\n",
       " (0.02238501016383313, 'Volume'),\n",
       " (0.017958235276345866, 'Close'),\n",
       " (0.017751160897510238, 'atr'),\n",
       " (0.01714408349537623, 'upper_BB'),\n",
       " (0.016111739610096057, 'upper_KC'),\n",
       " (0.016040189560598814, 'lower_BB'),\n",
       " (0.014727435909932108, 'High'),\n",
       " (0.014724252605615187, 'Low'),\n",
       " (0.014115512750053008, 'adx'),\n",
       " (0.013980336000872147, 'value'),\n",
       " (0.013964085611208894, 'lower_KC'),\n",
       " (0.01210054331778001, 'Open'),\n",
       " (0.0011866293205826167, 'squeeze_on')]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "listed = sorted(zip(rf_model.feature_importances_, X.columns), reverse = True)\n",
    "listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c55292cf-82c6-427c-ab5b-0bd56bc2e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec_model = EasyEnsembleClassifier(n_estimators = 100, random_state = 1)\n",
    "eec_model = eec_model.fit(X_trained_scaled, y_train)\n",
    "predictions = eec_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1607ed26-2eef-4f43-8e10-9c493ee0f28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "559e4713-cbc9-4e10-ac6a-eb1d73418eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77,  0],\n",
       "       [ 0, 92]], dtype=int64)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "736d3383-a95f-4aa4-83af-c31dd68e280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      1.00      1.00      1.00      1.00        77\n",
      "          1       1.00      1.00      1.00      1.00      1.00      1.00        92\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1.00      1.00      1.00       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7e85a100-e695-4c71-9b5b-eb6d7e8a4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add other classifier models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538aa14c-c2c2-4d06-bc7c-e1bf164deb56",
   "metadata": {},
   "source": [
    "# HW LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c521ccb0-a280-4d60-bdea-f5a98f9d7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ef6efe3b-f4e8-4b45-a2a2-d3a116b7577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "614a8fe2-d979-4b2d-b706-5764caf2087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 10\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 1\n",
    "target_column = 1\n",
    "X, y = window_data(df_stock, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a2877f3a-913d-4d51-ab93-901ddeb0a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9d358405-8752-4803-8dce-c43429eef6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "x_train_scaler = MinMaxScaler()\n",
    "x_test_scaler = MinMaxScaler()\n",
    "y_train_scaler = MinMaxScaler()\n",
    "y_test_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler for the Training Data\n",
    "x_train_scaler.fit(X_train)\n",
    "y_train_scaler.fit(y_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train = x_train_scaler.transform(X_train)\n",
    "y_train = y_train_scaler.transform(y_train)\n",
    "\n",
    "# Fit the scaler for the Testing Data\n",
    "x_test_scaler.fit(X_test)\n",
    "y_test_scaler.fit(y_test)\n",
    "\n",
    "# Scale the y_test data\n",
    "X_test = x_test_scaler.transform(X_test)\n",
    "y_test = y_test_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "85a121e3-fa58-4b3c-b39d-cf29f8006bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f3ad3c7a-be1d-42d7-b5d3-27eb4eaa8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "12e1b7f8-6bb3-4f0d-bc70-c5b3c2050280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "\n",
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 4\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "07ec44e2-5c2a-4967-a9d2-af723b03d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2165c85c-b51d-4087-8681-ec6fa8adbaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10, 4)             96        \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 10, 4)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 4)             144       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 10, 4)             0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 4)                 144       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 389\n",
      "Trainable params: 389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "02c04d56-fd81-4077-ad64-20dd2ff7854f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "464/464 [==============================] - 9s 10ms/step - loss: 0.0069\n",
      "Epoch 2/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0158\n",
      "Epoch 3/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0170\n",
      "Epoch 4/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0148\n",
      "Epoch 5/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0104\n",
      "Epoch 6/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0078\n",
      "Epoch 7/10\n",
      "464/464 [==============================] - 5s 11ms/step - loss: 0.0079\n",
      "Epoch 8/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0062\n",
      "Epoch 9/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0073\n",
      "Epoch 10/10\n",
      "464/464 [==============================] - 5s 10ms/step - loss: 0.0055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb3820d910>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "196151a3-bc7d-4936-8a97-6de36ee2a0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 5ms/step - loss: 0.0237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.023683160543441772"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "025ea32f-4d13-4741-9ad9-b08a63b479a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7005d711-4f67-488e-a6cc-e3ce20f8c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_profit = y_test_scaler.inverse_transform(predicted)\n",
    "real_profit = y_test_scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6549b76a-60de-415d-8cb6-753e7d5d73e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-16</th>\n",
       "      <td>120.605867</td>\n",
       "      <td>122.079269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-19</th>\n",
       "      <td>120.954158</td>\n",
       "      <td>122.562271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20</th>\n",
       "      <td>119.829691</td>\n",
       "      <td>123.521049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21</th>\n",
       "      <td>118.396763</td>\n",
       "      <td>124.355736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>118.128081</td>\n",
       "      <td>125.271225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Real   Predicted\n",
       "Date                              \n",
       "2020-10-16  120.605867  122.079269\n",
       "2020-10-19  120.954158  122.562271\n",
       "2020-10-20  119.829691  123.521049\n",
       "2020-10-21  118.396763  124.355736\n",
       "2020-10-22  118.128081  125.271225"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_profit.ravel(),\n",
    "    \"Predicted\": predicted_profit.ravel()\n",
    "}, index = df_stock.index[-len(real_profit): ]) \n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "160fa9f0-3639-4cd5-a6c6-b048ac53dc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dba0bcb6fd34eb197e8e9b777e039a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Actual Vs. Predicted AAPL CLosing Prices'}, xlabel='Date'>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "stocks.plot(title=\"Actual Vs. Predicted AAPL CLosing Prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb007f-e75d-4474-a43a-ed6a88fc1761",
   "metadata": {},
   "source": [
    "# Multifeature LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "25f8233e-25cc-4500-a001-e9388c381a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi feature LSTM\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "dc96fb06-5b43-4617-b388-57b4b8003796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d8d67608-bd33-491c-9d79-abeb9ee62d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.058682   0.061741   0.062136   0.068111   0.811012        0.0   \n",
      "2   0.069809   0.075598   0.070849   0.082350   0.864583        0.0   \n",
      "3   0.082450   0.078807   0.076809   0.079396   0.822917        0.0   \n",
      "4   0.077398   0.073557   0.075368   0.077334   0.778274        0.0   \n",
      "5   0.086286   0.083355   0.084361   0.090595   0.800595        0.0   \n",
      "\n",
      "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...  var15(t)  var16(t)  \\\n",
      "1        0.0   0.138116   0.054215    0.053033  ...  0.087825  0.159289   \n",
      "2        0.0   0.133638   0.051771    0.101281  ...  0.083534  0.164021   \n",
      "3        0.0   0.125897   0.051191    0.076669  ...  0.079413  0.155980   \n",
      "4        0.0   0.114647   0.053328    0.041509  ...  0.076689  0.144165   \n",
      "5        0.0   0.109609   0.053665    0.049908  ...  0.075692  0.151877   \n",
      "\n",
      "   var17(t)  var18(t)  var19(t)  var20(t)  var21(t)  var22(t)  var23(t)  \\\n",
      "1  0.170127  0.739876  0.656497       0.0       1.0  0.334559  0.672555   \n",
      "2  0.174467  0.658938  0.653820       0.0       1.0  0.338749  0.486868   \n",
      "3  0.159164  0.643341  0.645210       0.0       1.0  0.348060  0.496044   \n",
      "4  0.276951  0.624723  0.637072       0.0       1.0  0.373463  0.658425   \n",
      "5  0.227566  0.675390  0.611300       0.0       1.0  0.381007  0.340739   \n",
      "\n",
      "   var24(t)  \n",
      "1       1.0  \n",
      "2       0.0  \n",
      "3       0.0  \n",
      "4       1.0  \n",
      "5       0.0  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "values = df_stock.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "#reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "beda5495-03b2-465c-83c2-1273400c1b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 1, 47) (303,) (370, 1, 47) (370,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_days = 303\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a6770828-a34a-496d-8049-39fd4fcd4984",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "16/16 - 3s - loss: 0.5733 - accuracy: 0.4290 - val_loss: 0.5249 - val_accuracy: 0.4730\n",
      "Epoch 2/60\n",
      "16/16 - 0s - loss: 0.5408 - accuracy: 0.4290 - val_loss: 0.5160 - val_accuracy: 0.4730\n",
      "Epoch 3/60\n",
      "16/16 - 0s - loss: 0.5282 - accuracy: 0.4455 - val_loss: 0.5077 - val_accuracy: 0.4459\n",
      "Epoch 4/60\n",
      "16/16 - 0s - loss: 0.5269 - accuracy: 0.4488 - val_loss: 0.4991 - val_accuracy: 0.5162\n",
      "Epoch 5/60\n",
      "16/16 - 0s - loss: 0.5150 - accuracy: 0.4983 - val_loss: 0.4912 - val_accuracy: 0.5216\n",
      "Epoch 6/60\n",
      "16/16 - 0s - loss: 0.4899 - accuracy: 0.5380 - val_loss: 0.4821 - val_accuracy: 0.5270\n",
      "Epoch 7/60\n",
      "16/16 - 0s - loss: 0.5050 - accuracy: 0.5017 - val_loss: 0.4760 - val_accuracy: 0.5270\n",
      "Epoch 8/60\n",
      "16/16 - 0s - loss: 0.4807 - accuracy: 0.5380 - val_loss: 0.4778 - val_accuracy: 0.5270\n",
      "Epoch 9/60\n",
      "16/16 - 0s - loss: 0.4854 - accuracy: 0.5050 - val_loss: 0.4766 - val_accuracy: 0.5270\n",
      "Epoch 10/60\n",
      "16/16 - 0s - loss: 0.4776 - accuracy: 0.5215 - val_loss: 0.4861 - val_accuracy: 0.5270\n",
      "Epoch 11/60\n",
      "16/16 - 0s - loss: 0.4850 - accuracy: 0.5281 - val_loss: 0.4925 - val_accuracy: 0.5270\n",
      "Epoch 12/60\n",
      "16/16 - 0s - loss: 0.4754 - accuracy: 0.5314 - val_loss: 0.4735 - val_accuracy: 0.5270\n",
      "Epoch 13/60\n",
      "16/16 - 0s - loss: 0.4707 - accuracy: 0.5281 - val_loss: 0.4697 - val_accuracy: 0.5270\n",
      "Epoch 14/60\n",
      "16/16 - 0s - loss: 0.4575 - accuracy: 0.5446 - val_loss: 0.4621 - val_accuracy: 0.5270\n",
      "Epoch 15/60\n",
      "16/16 - 0s - loss: 0.4438 - accuracy: 0.5644 - val_loss: 0.4604 - val_accuracy: 0.5270\n",
      "Epoch 16/60\n",
      "16/16 - 0s - loss: 0.4392 - accuracy: 0.5842 - val_loss: 0.4593 - val_accuracy: 0.5270\n",
      "Epoch 17/60\n",
      "16/16 - 0s - loss: 0.4640 - accuracy: 0.5248 - val_loss: 0.4570 - val_accuracy: 0.5270\n",
      "Epoch 18/60\n",
      "16/16 - 0s - loss: 0.4439 - accuracy: 0.5578 - val_loss: 0.4550 - val_accuracy: 0.5270\n",
      "Epoch 19/60\n",
      "16/16 - 0s - loss: 0.4488 - accuracy: 0.5644 - val_loss: 0.4535 - val_accuracy: 0.5270\n",
      "Epoch 20/60\n",
      "16/16 - 0s - loss: 0.4560 - accuracy: 0.5347 - val_loss: 0.4524 - val_accuracy: 0.5270\n",
      "Epoch 21/60\n",
      "16/16 - 0s - loss: 0.4798 - accuracy: 0.5116 - val_loss: 0.4513 - val_accuracy: 0.5270\n",
      "Epoch 22/60\n",
      "16/16 - 0s - loss: 0.4756 - accuracy: 0.5116 - val_loss: 0.4490 - val_accuracy: 0.5270\n",
      "Epoch 23/60\n",
      "16/16 - 0s - loss: 0.4680 - accuracy: 0.5182 - val_loss: 0.4481 - val_accuracy: 0.5270\n",
      "Epoch 24/60\n",
      "16/16 - 0s - loss: 0.4883 - accuracy: 0.4917 - val_loss: 0.4463 - val_accuracy: 0.5270\n",
      "Epoch 25/60\n",
      "16/16 - 0s - loss: 0.4464 - accuracy: 0.5644 - val_loss: 0.4454 - val_accuracy: 0.5270\n",
      "Epoch 26/60\n",
      "16/16 - 0s - loss: 0.4747 - accuracy: 0.4917 - val_loss: 0.4451 - val_accuracy: 0.5270\n",
      "Epoch 27/60\n",
      "16/16 - 0s - loss: 0.4557 - accuracy: 0.5380 - val_loss: 0.4407 - val_accuracy: 0.5270\n",
      "Epoch 28/60\n",
      "16/16 - 0s - loss: 0.4350 - accuracy: 0.5776 - val_loss: 0.4384 - val_accuracy: 0.5270\n",
      "Epoch 29/60\n",
      "16/16 - 0s - loss: 0.4606 - accuracy: 0.4950 - val_loss: 0.4388 - val_accuracy: 0.5297\n",
      "Epoch 30/60\n",
      "16/16 - 0s - loss: 0.4295 - accuracy: 0.5875 - val_loss: 0.4373 - val_accuracy: 0.5324\n",
      "Epoch 31/60\n",
      "16/16 - 0s - loss: 0.4526 - accuracy: 0.5281 - val_loss: 0.4344 - val_accuracy: 0.5324\n",
      "Epoch 32/60\n",
      "16/16 - 0s - loss: 0.4725 - accuracy: 0.4983 - val_loss: 0.4323 - val_accuracy: 0.5514\n",
      "Epoch 33/60\n",
      "16/16 - 0s - loss: 0.4587 - accuracy: 0.5446 - val_loss: 0.4304 - val_accuracy: 0.5568\n",
      "Epoch 34/60\n",
      "16/16 - 0s - loss: 0.4551 - accuracy: 0.5314 - val_loss: 0.4303 - val_accuracy: 0.5757\n",
      "Epoch 35/60\n",
      "16/16 - 0s - loss: 0.4429 - accuracy: 0.5446 - val_loss: 0.4313 - val_accuracy: 0.6351\n",
      "Epoch 36/60\n",
      "16/16 - 0s - loss: 0.4453 - accuracy: 0.5479 - val_loss: 0.4273 - val_accuracy: 0.6270\n",
      "Epoch 37/60\n",
      "16/16 - 0s - loss: 0.4556 - accuracy: 0.5149 - val_loss: 0.4235 - val_accuracy: 0.6405\n",
      "Epoch 38/60\n",
      "16/16 - 0s - loss: 0.4637 - accuracy: 0.5083 - val_loss: 0.4224 - val_accuracy: 0.6919\n",
      "Epoch 39/60\n",
      "16/16 - 0s - loss: 0.4205 - accuracy: 0.5842 - val_loss: 0.4200 - val_accuracy: 0.7216\n",
      "Epoch 40/60\n",
      "16/16 - 0s - loss: 0.4546 - accuracy: 0.5248 - val_loss: 0.4183 - val_accuracy: 0.7405\n",
      "Epoch 41/60\n",
      "16/16 - 0s - loss: 0.4341 - accuracy: 0.5545 - val_loss: 0.4122 - val_accuracy: 0.7270\n",
      "Epoch 42/60\n",
      "16/16 - 0s - loss: 0.4585 - accuracy: 0.5281 - val_loss: 0.4131 - val_accuracy: 0.7351\n",
      "Epoch 43/60\n",
      "16/16 - 0s - loss: 0.4537 - accuracy: 0.5314 - val_loss: 0.4081 - val_accuracy: 0.7378\n",
      "Epoch 44/60\n",
      "16/16 - 0s - loss: 0.4226 - accuracy: 0.5710 - val_loss: 0.4044 - val_accuracy: 0.7459\n",
      "Epoch 45/60\n",
      "16/16 - 0s - loss: 0.4247 - accuracy: 0.5644 - val_loss: 0.4009 - val_accuracy: 0.7784\n",
      "Epoch 46/60\n",
      "16/16 - 0s - loss: 0.4339 - accuracy: 0.5545 - val_loss: 0.3943 - val_accuracy: 0.7838\n",
      "Epoch 47/60\n",
      "16/16 - 0s - loss: 0.4386 - accuracy: 0.5380 - val_loss: 0.3890 - val_accuracy: 0.7811\n",
      "Epoch 48/60\n",
      "16/16 - 0s - loss: 0.4503 - accuracy: 0.5479 - val_loss: 0.3807 - val_accuracy: 0.7838\n",
      "Epoch 49/60\n",
      "16/16 - 0s - loss: 0.4216 - accuracy: 0.5842 - val_loss: 0.3746 - val_accuracy: 0.7811\n",
      "Epoch 50/60\n",
      "16/16 - 0s - loss: 0.4061 - accuracy: 0.6073 - val_loss: 0.3701 - val_accuracy: 0.7892\n",
      "Epoch 51/60\n",
      "16/16 - 0s - loss: 0.4235 - accuracy: 0.5743 - val_loss: 0.3710 - val_accuracy: 0.8189\n",
      "Epoch 52/60\n",
      "16/16 - 0s - loss: 0.4271 - accuracy: 0.5611 - val_loss: 0.3664 - val_accuracy: 0.8216\n",
      "Epoch 53/60\n",
      "16/16 - 0s - loss: 0.4197 - accuracy: 0.5875 - val_loss: 0.3663 - val_accuracy: 0.8270\n",
      "Epoch 54/60\n",
      "16/16 - 0s - loss: 0.4290 - accuracy: 0.5974 - val_loss: 0.3526 - val_accuracy: 0.7946\n",
      "Epoch 55/60\n",
      "16/16 - 0s - loss: 0.4013 - accuracy: 0.5941 - val_loss: 0.3543 - val_accuracy: 0.8108\n",
      "Epoch 56/60\n",
      "16/16 - 0s - loss: 0.4157 - accuracy: 0.5644 - val_loss: 0.3556 - val_accuracy: 0.8135\n",
      "Epoch 57/60\n",
      "16/16 - 0s - loss: 0.4111 - accuracy: 0.5941 - val_loss: 0.3392 - val_accuracy: 0.8189\n",
      "Epoch 58/60\n",
      "16/16 - 0s - loss: 0.3740 - accuracy: 0.6898 - val_loss: 0.3403 - val_accuracy: 0.8243\n",
      "Epoch 59/60\n",
      "16/16 - 0s - loss: 0.4014 - accuracy: 0.6370 - val_loss: 0.3439 - val_accuracy: 0.7973\n",
      "Epoch 60/60\n",
      "16/16 - 0s - loss: 0.3876 - accuracy: 0.6304 - val_loss: 0.3268 - val_accuracy: 0.8243\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "#model.add(Dropout(0.3))\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=60, batch_size=20, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6f968090-6e7e-4615-8dfe-90b2f674812c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03503a7b22c74689ae603fcf96211777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "fig = pyplot.figure()\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "178eb02e-2eb2-4f66-a246-91608e24e4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 30.047\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "#self.synaptic_weights = self.synaptic_weights + adjustment\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, :]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat.reshape(740,24))\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, :]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y.reshape(740,24))\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b59c2f-6e65-4fad-b930-3da73fadd062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f3d47-465c-4b8b-80a2-d6c19bf937e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(inv_yhat.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849d3fc-0cdd-4b33-9487-b228e9716876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298577c-2c0a-42c1-9c8c-7828f4003a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe137b-8af6-4fc3-ab37-76c5fb4abc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5477282-3cf6-4cda-ba47-1eb3dedea367",
   "metadata": {},
   "outputs": [],
   "source": [
    "screened_list = []\n",
    "stock_list = ['AAPL','TSLA','MSFT','AMZN']\n",
    "\n",
    "for stock_code in stock_list:\n",
    "    df = yf.download(stock_code, start='2020-01-01', threads= False)\n",
    "    if enter_long | enter_short:\n",
    "        screened_list.append(stock_code)\n",
    "    \n",
    "if screened_list:\n",
    "  print(screened_list)\n",
    "else:\n",
    "  print('No stock fits the indicator entry requirement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eac3ad-fe48-433c-9b42-ec00d89f41c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(mpf.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a108b7-8944-4efd-a9d1-0df0f8760a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['NFLX', 'AAPL', 'FB', 'GOOG', 'AMZN']\n",
    "\n",
    "ticker_dict_1mo = {}\n",
    "ticker_dict_1wk = {}\n",
    "ticker_dict_1d = {}\n",
    "for stock in tickers:\n",
    "    ticker_dict_1mo[stock] = yf.Ticker(stock).history(period=\"10y\", interval='1mo')\n",
    "    ticker_dict_1mo[stock][\"ticker\"] = stock\n",
    "    ticker_dict_1wk[stock] = yf.Ticker(stock).history(period=\"10y\", interval='1wk')\n",
    "    ticker_dict_1wk[stock]['ticker'] = stock\n",
    "    ticker_dict_1d[stock] = yf.Ticker(stock).history(period=\"10y\", interval='1d')\n",
    "    ticker_dict_1d[stock]['ticker'] = stock\n",
    "    \n",
    "ticker_dict_1mo['AAPL']\n",
    "\n",
    "monthly_data = pd.concat(ticker_dict_1mo.values())\n",
    "monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81a70b-4415-4fab-9f55-7680a05b5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Bollinger Bands\n",
    "m_avg_mo = {}\n",
    "m_avg_wk = {}\n",
    "m_avg_d = {}\n",
    "m_std_mo = {}\n",
    "m_std_wk = {}\n",
    "m_std_d = {}\n",
    "\n",
    "for stock in tickers:\n",
    "    # moving average\n",
    "    m_avg_mo[stock] = ticker_dict_1mo[stock]['Close'].rolling(window=length).mean()\n",
    "    m_avg_wk[stock] = ticker_dict_1wk[stock]['Close'].rolling(window=length).mean()\n",
    "    m_avg_d[stock] = ticker_dict_1d[stock]['Close'].rolling(window=length).mean()\n",
    "    # standard deviation\n",
    "    m_std_mo[stock] = ticker_dict_1mo[stock]['Close'].rolling(window=length).std(ddof=0)\n",
    "    m_std_wk[stock] = ticker_dict_1wk[stock]['Close'].rolling(window=length).std(ddof=0)\n",
    "    m_std_d[stock] = ticker_dict_1d[stock]['Close'].rolling(window=length).std(ddof=0)\n",
    "    # upper Bollinger Bands\n",
    "    ticker_dict_1mo[stock]['upper_BB'] = m_avg_mo[stock] + mult * m_std_mo[stock]\n",
    "    ticker_dict_1wk[stock]['upper_BB'] = m_avg_wk[stock] + mult * m_std_wk[stock]\n",
    "    ticker_dict_1d[stock]['upper_BB'] = m_avg_d[stock] + mult * m_std_d[stock]\n",
    "# lower Bollinger Bands \n",
    "    ticker_dict_1mo[stock]['lower_BB'] = m_avg_mo[stock] - mult * m_std_mo[stock]\n",
    "    ticker_dict_1wk[stock]['lower_BB'] = m_avg_wk[stock] - mult * m_std_wk[stock]\n",
    "    ticker_dict_1d[stock]['lower_BB'] = m_avg_d[stock] - mult * m_std_d[stock]\n",
    "    \n",
    "ticker_dict_1d[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b424fc4-3b5a-4c8a-aca2-754f85c21268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Keltner Channel\n",
    "range_ma_mo = {}\n",
    "range_ma_wk = {}\n",
    "range_ma_d = {}\n",
    "\n",
    "for stock in tickers:\n",
    "    # first we need to calculate True Range (monthly)\n",
    "    ticker_dict_1mo[stock]['tr0'] = abs(ticker_dict_1mo[stock][\"High\"] - ticker_dict_1mo[stock][\"Low\"])\n",
    "    ticker_dict_1mo[stock]['tr1'] = abs(ticker_dict_1mo[stock][\"High\"] - ticker_dict_1mo[stock][\"Close\"].shift())\n",
    "    ticker_dict_1mo[stock]['tr2'] = abs(ticker_dict_1mo[stock][\"Low\"] - ticker_dict_1mo[stock][\"Close\"].shift())\n",
    "    ticker_dict_1mo[stock]['tr'] = ticker_dict_1mo[stock][['tr0', 'tr1', 'tr2']].max(axis=1)\n",
    "    \n",
    "    # first we need to calculate True Range (weekly)\n",
    "    ticker_dict_1wk[stock]['tr0'] = abs(ticker_dict_1wk[stock][\"High\"] - ticker_dict_1wk[stock][\"Low\"])\n",
    "    ticker_dict_1wk[stock]['tr1'] = abs(ticker_dict_1wk[stock][\"High\"] - ticker_dict_1wk[stock][\"Close\"].shift())\n",
    "    ticker_dict_1wk[stock]['tr2'] = abs(ticker_dict_1wk[stock][\"Low\"] - ticker_dict_1wk[stock][\"Close\"].shift())\n",
    "    ticker_dict_1wk[stock]['tr'] = ticker_dict_1wk[stock][['tr0', 'tr1', 'tr2']].max(axis=1)\n",
    "    \n",
    "    # first we need to calculate True Range (daily)\n",
    "    ticker_dict_1d[stock]['tr0'] = abs(ticker_dict_1d[stock][\"High\"] - ticker_dict_1d[stock][\"Low\"])\n",
    "    ticker_dict_1d[stock]['tr1'] = abs(ticker_dict_1d[stock][\"High\"] - ticker_dict_1d[stock][\"Close\"].shift())\n",
    "    ticker_dict_1d[stock]['tr2'] = abs(ticker_dict_1d[stock][\"Low\"] - ticker_dict_1d[stock][\"Close\"].shift())\n",
    "    ticker_dict_1d[stock]['tr'] = ticker_dict_1d[stock][['tr0', 'tr1', 'tr2']].max(axis=1)\n",
    "\n",
    "    # moving average of the TR\n",
    "    range_ma_mo[stock] = ticker_dict_1mo[stock]['tr'].rolling(window=length_KC).mean()\n",
    "    range_ma_wk[stock] = ticker_dict_1wk[stock]['tr'].rolling(window=length_KC).mean()\n",
    "    range_ma_d[stock] = ticker_dict_1d[stock]['tr'].rolling(window=length_KC).mean()\n",
    "    \n",
    "    # upper Keltner Channel\n",
    "    ticker_dict_1mo[stock]['upper_KC'] = m_avg_mo[stock] + range_ma_mo[stock] * mult_KC\n",
    "    ticker_dict_1wk[stock]['upper_KC'] = m_avg_wk[stock] + range_ma_wk[stock] * mult_KC\n",
    "    ticker_dict_1d[stock]['upper_KC'] = m_avg_d[stock] + range_ma_d[stock] * mult_KC\n",
    "    \n",
    "    # lower Keltner Channel\n",
    "    ticker_dict_1mo[stock]['lower_KC'] = m_avg_mo[stock] - range_ma_mo[stock] * mult_KC\n",
    "    ticker_dict_1wk[stock]['lower_KC'] = m_avg_wk[stock] - range_ma_wk[stock] * mult_KC\n",
    "    ticker_dict_1d[stock]['lower_KC'] = m_avg_d[stock] - range_ma_d[stock] * mult_KC\n",
    "\n",
    "ticker_dict_1d[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac207c36-a48e-441c-97f2-6d562208cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for 'squeeze'\n",
    "for stock in tickers:\n",
    "    #monthly\n",
    "    ticker_dict_1mo[stock]['squeeze_on'] = (ticker_dict_1mo[stock]['lower_BB'] > ticker_dict_1mo[stock]['lower_KC']) | (ticker_dict_1mo[stock]['upper_BB'] < ticker_dict_1mo[stock]['upper_KC'])\n",
    "    ticker_dict_1mo[stock]['squeeze_off'] = (ticker_dict_1mo[stock]['lower_BB'] < ticker_dict_1mo[stock]['lower_KC']) | (ticker_dict_1mo[stock]['upper_BB'] > ticker_dict_1mo[stock]['upper_KC'])\n",
    "    \n",
    "    #weekly\n",
    "    ticker_dict_1wk[stock]['squeeze_on'] = (ticker_dict_1wk[stock]['lower_BB'] > ticker_dict_1wk[stock]['lower_KC']) | (ticker_dict_1wk[stock]['upper_BB'] < ticker_dict_1wk[stock]['upper_KC'])\n",
    "    ticker_dict_1wk[stock]['squeeze_off'] = (ticker_dict_1wk[stock]['lower_BB'] < ticker_dict_1wk[stock]['lower_KC']) | (ticker_dict_1wk[stock]['upper_BB'] > ticker_dict_1wk[stock]['upper_KC'])\n",
    "    \n",
    "    #daily\n",
    "    ticker_dict_1d[stock]['squeeze_on'] = (ticker_dict_1d[stock]['lower_BB'] > ticker_dict_1d[stock]['lower_KC']) | (ticker_dict_1d[stock]['upper_BB'] < ticker_dict_1d[stock]['upper_KC'])\n",
    "    ticker_dict_1d[stock]['squeeze_off'] = (ticker_dict_1d[stock]['lower_BB'] < ticker_dict_1d[stock]['lower_KC']) | (ticker_dict_1d[stock]['upper_BB'] > ticker_dict_1d[stock]['upper_KC'])\n",
    "    \n",
    "ticker_dict_1d[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841b567-8406-46b1-8482-5c4164bba7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum\n",
    "highest_mo = {}\n",
    "highest_wk = {}\n",
    "highest_d = {}\n",
    "lowest_mo = {}\n",
    "lowest_wk = {}\n",
    "lowest_d = {}\n",
    "m1_mo = {}\n",
    "m1_wk = {}\n",
    "m1_d = {}\n",
    "fit_y_mo = {}\n",
    "fit_y_wk = {}\n",
    "fit_y_d = {}\n",
    "\n",
    "\n",
    "for stock in tickers:\n",
    "    #monthly\n",
    "    highest_mo[stock] = ticker_dict_1mo[stock]['High'].rolling(window = length_KC).max()\n",
    "    lowest_mo[stock] = ticker_dict_1mo[stock]['Low'].rolling(window = length_KC).min()\n",
    "    m1_mo[stock] = (highest_mo[stock] + lowest_mo[stock]) / 2\n",
    "    ticker_dict_1mo[stock]['value'] = (ticker_dict_1mo[stock]['Close'] - (m1_mo[stock] + m_avg_mo[stock])/2)\n",
    "    fit_y_mo[stock] = np.array(range(0,length_KC))\n",
    "    ticker_dict_1mo[stock]['value'] = ticker_dict_1mo[stock]['value'].rolling(window = length_KC).apply(lambda x : np.polyfit(fit_y_mo[stock], x, 1)[0] * (length_KC-1) +\n",
    "    np.polyfit(fit_y_mo[stock], x, 1)[1], raw=True)\n",
    "    \n",
    "    #weekly\n",
    "    highest_wk[stock] = ticker_dict_1wk[stock]['High'].rolling(window = length_KC).max()\n",
    "    lowest_wk[stock] = ticker_dict_1wk[stock]['Low'].rolling(window = length_KC).min()\n",
    "    m1_wk[stock] = (highest_wk[stock] + lowest_wk[stock]) / 2\n",
    "    ticker_dict_1wk[stock]['value'] = (ticker_dict_1wk[stock]['Close'] - (m1_wk[stock] + m_avg_wk[stock])/2)\n",
    "    fit_y_wk[stock] = np.array(range(0,length_KC))\n",
    "    ticker_dict_1wk[stock]['value'] = ticker_dict_1wk[stock]['value'].rolling(window = length_KC).apply(lambda x : np.polyfit(fit_y_wk[stock], x, 1)[0] * (length_KC-1) +\n",
    "    np.polyfit(fit_y_wk[stock], x, 1)[1], raw=True)\n",
    "    \n",
    "    #daily\n",
    "    highest_d[stock] = ticker_dict_1d[stock]['High'].rolling(window = length_KC).max()\n",
    "    lowest_d[stock] = ticker_dict_1d[stock]['Low'].rolling(window = length_KC).min()\n",
    "    m1_d[stock] = (highest_d[stock] + lowest_d[stock]) / 2\n",
    "    ticker_dict_1d[stock]['value'] = (ticker_dict_1d[stock]['Close'] - (m1_d[stock] + m_avg_d[stock])/2)\n",
    "    fit_y_d[stock] = np.array(range(0,length_KC))\n",
    "    ticker_dict_1d[stock]['value'] = ticker_dict_1d[stock]['value'].rolling(window = length_KC).apply(lambda x : np.polyfit(fit_y_d[stock], x, 1)[0] * (length_KC-1) +\n",
    "    np.polyfit(fit_y_d[stock], x, 1)[1], raw=True)\n",
    "    \n",
    "ticker_dict_1d[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416e4ae-c63b-499d-a420-e3e5a9452db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_cond1_mo = {}\n",
    "long_cond2_mo = {}\n",
    "enter_long_mo = {}\n",
    "short_cond1_mo = {}\n",
    "short_cond2_mo = {}\n",
    "enter_short_mo = {}\n",
    "long_cond1_wk = {}\n",
    "long_cond2_wk = {}\n",
    "enter_long_wk = {}\n",
    "short_cond1_wk = {}\n",
    "short_cond2_wk = {}\n",
    "enter_short_wk = {}\n",
    "long_cond1_d = {}\n",
    "long_cond2_d = {}\n",
    "enter_long_d = {}\n",
    "short_cond1_d = {}\n",
    "short_cond2_d = {}\n",
    "enter_short_d = {}\n",
    "\n",
    "for stock in tickers:\n",
    "    #monthly\n",
    "    # entry point for long position:\n",
    "    # 1. black cross becomes gray (the squeeze is released)\n",
    "    long_cond1_mo[stock] = (ticker_dict_1mo[stock]['squeeze_off'][-2] == False) | (ticker_dict_1mo[stock]['squeeze_off'][-1] == True) \n",
    "    # 2. bar value is positive => the bar is light green\n",
    "    long_cond2_mo[stock] = ticker_dict_1mo[stock]['value'][-1] > 0\n",
    "\n",
    "    enter_long_mo[stock] = long_cond1_mo[stock] and long_cond2_mo[stock]\n",
    "    # entry point for short position:\n",
    "    # 1. black cross becomes gray (the squeeze is released)\n",
    "    short_cond1_mo[stock] = (ticker_dict_1mo[stock]['squeeze_off'][-2] == False) | (ticker_dict_1mo[stock]['squeeze_off'][-1] == True) \n",
    "    # 2. bar value is negative => the bar is light red \n",
    "    short_cond2_mo[stock] = ticker_dict_1mo[stock]['value'][-1] < 0\n",
    "    enter_short_mo[stock] = short_cond1_mo[stock] and short_cond2_mo[stock]\n",
    "    \n",
    "    #weekly\n",
    "    # entry point for long position:\n",
    "    # 1. black cross becomes gray (the squeeze is released)\n",
    "    long_cond1_wk[stock] = (ticker_dict_1wk[stock]['squeeze_off'][-2] == False) | (ticker_dict_1wk[stock]['squeeze_off'][-1] == True) \n",
    "    # 2. bar value is positive => the bar is light green\n",
    "    long_cond2_wk[stock] = ticker_dict_1wk[stock]['value'][-1] > 0\n",
    "\n",
    "    enter_long_wk[stock] = long_cond1_wk[stock] and long_cond2_wk[stock]\n",
    "    # entry point for short position:\n",
    "    # 1. black cross becomes gray (the squeeze is released)\n",
    "    short_cond1_wk[stock] = (ticker_dict_1wk[stock]['squeeze_off'][-2] == False) | (ticker_dict_1wk[stock]['squeeze_off'][-1] == True) \n",
    "    # 2. bar value is negative => the bar is light red \n",
    "    short_cond2_wk[stock] = ticker_dict_1wk[stock]['value'][-1] < 0\n",
    "    enter_short_wk[stock] = short_cond1_wk[stock] and short_cond2_wk[stock]\n",
    "    \n",
    "    #daily\n",
    "    # entry point for long position:\n",
    "    # 1. black cross becomes gray (the squeeze is released)\n",
    "    long_cond1_d[stock] = (ticker_dict_1d[stock]['squeeze_off'][-2] == False) | (ticker_dict_1d[stock]['squeeze_off'][-1] == True) \n",
    "    # 2. bar value is positive => the bar is light green\n",
    "    long_cond2_d[stock] = ticker_dict_1d[stock]['value'][-1] > 0\n",
    "\n",
    "    enter_long_d[stock] = long_cond1_d[stock] and long_cond2_d[stock]\n",
    "    # entry point for short position:\n",
    "    # 1. black cross becomes gray (the squeeze is released)\n",
    "    short_cond1_d[stock] = (ticker_dict_1d[stock]['squeeze_off'][-2] == False) | (ticker_dict_1d[stock]['squeeze_off'][-1] == True) \n",
    "    # 2. bar value is negative => the bar is light red \n",
    "    short_cond2_d[stock] = ticker_dict_1d[stock]['value'][-1] < 0\n",
    "    enter_short_d[stock] = short_cond1_d[stock] and short_cond2_d[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dbf612-820c-4eab-8df4-77f02df44d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohcl_mo = {}\n",
    "ohcl_wk = {}\n",
    "ohcl_d = {}\n",
    "\n",
    "for stock in tickers:\n",
    "    ohcl_mo[stock] = ticker_dict_1mo[stock][['Open', 'High', 'Close', 'Low']]\n",
    "    ohcl_wk[stock] = ticker_dict_1wk[stock][['Open', 'High', 'Close', 'Low']]\n",
    "    ohcl_d[stock] = ticker_dict_1d[stock][['Open', 'High', 'Close', 'Low']]\n",
    "    \n",
    "ohcl_d[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db2b96-805f-4a9c-bb9b-20cc85d516b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_mo = {}\n",
    "val_mo = {}\n",
    "ind_wk = {}\n",
    "val_wk = {}\n",
    "ind_d = {}\n",
    "val_d = {}\n",
    "\n",
    "for stock in tickers:\n",
    "    # add colors for the 'value bar'\n",
    "    colors_mo = []\n",
    "    for ind_mo[stock], val_mo[stock] in enumerate(ticker_dict_1mo[stock]['value']):\n",
    "        if val_mo[stock] >= 0:\n",
    "            color_mo = 'blue'\n",
    "        if val_mo[stock] > ticker_dict_1mo[stock]['value'][ind_mo[stock]-1]:\n",
    "            color_mo = 'cyan'\n",
    "        else:\n",
    "            color_mo = 'yellow'\n",
    "        if val_mo[stock] < ticker_dict_1mo[stock]['value'][ind_mo[stock]-1]:\n",
    "            color_mo='red'\n",
    "        colors_mo.append(color)\n",
    "        \n",
    "    #colors_mo = []\n",
    "    #for ind_mo[stock], val_mo[stock] in enumerate(ticker_dict_1mo[stock]['value']):\n",
    "       # if val_mo[stock] >= 0:\n",
    "            #color_mo = 'green'\n",
    "        #if val_mo[stock] > ticker_dict_1mo[stock]['value'][ind_mo[stock]-1]:\n",
    "           # color_mo = 'lime'\n",
    "       # else:\n",
    "            #color_mo = 'maroon'\n",
    "        #if val_mo[stock] < ticker_dict_1mo[stock]['value'][ind_mo[stock]-1]:\n",
    "           # color_mo='red'\n",
    "      #  colors_mo.append(color)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852033c-8377-477a-bfab-b1cd99b6907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "from panel.interact import interact\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "def figure_stock_mo(stock):\n",
    "    apds = [mpf.make_addplot(ticker_dict_1mo[stock]['value'], panel=1, type='bar', color=colors_mo, alpha=0.8, secondary_y=False),\n",
    "            mpf.make_addplot([0] * len(ticker_dict_1mo[stock]), panel=1, type='scatter', marker='o', markersize=50, color=['gray' if s else 'red' for s in ticker_dict_1mo[stock]['squeeze_off']], secondary_y=False),\n",
    "            mpf.make_addplot(ticker_dict_1mo[stock][['upper_BB']], color = 'red'),\n",
    "            mpf.make_addplot(ticker_dict_1mo[stock][['lower_BB']], color = 'red'),\n",
    "            mpf.make_addplot(ticker_dict_1mo[stock][['upper_KC']], color = 'blue'),\n",
    "            mpf.make_addplot(ticker_dict_1mo[stock][['lower_KC']], color = 'blue')]\n",
    "\n",
    "    # plot ohcl with subplots\n",
    "    fig, axes = mpf.plot(ohcl_mo[stock], \n",
    "              volume_panel = 2,\n",
    "              figratio=(2,1),\n",
    "              figscale=1,\n",
    "              mav = (8,21,34),\n",
    "              type='candle', \n",
    "              addplot=apds,\n",
    "              returnfig=True)\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "ticker = monthly_data[\"ticker\"].unique()\n",
    "interact(figure_stock_mo, stock=ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827feefe-c17d-43dc-ae45-45ed501bb810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
